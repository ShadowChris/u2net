{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, CenterCrop\n",
    "import torchvision.transforms.functional as F\n",
    "from pymatting import *\n",
    "\n",
    "from lib import U2NET_full\n",
    "from lib.utils.oom import free_up_memory\n",
    "import cv2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_samples(folder_path='./dataset/demo'):\n",
    "    assert os.path.isdir(folder_path), f'Unable to open {folder_path}'\n",
    "    samples = glob(os.path.join(folder_path, f'*.jpg'))\n",
    "    print(os.getcwd())\n",
    "    return samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\data\\workspace\\python\\wanxiang-ai\\u-2-net-portrait\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "samples = load_samples()\n",
    "# model_select, sample_select = create_ui(samples)\n",
    "model_select = 'checkpoint.pth'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def square_pad(image, fill=255):\n",
    "    w, h = image.size\n",
    "    max_wh = np.max([w, h])\n",
    "    hp = int((max_wh - w) / 2)\n",
    "    vp = int((max_wh - h) / 2)\n",
    "    padding = (hp, vp, hp, vp)\n",
    "    return F.pad(image, padding, fill, 'constant')\n",
    "\n",
    "\n",
    "def get_transform():\n",
    "    transforms = []\n",
    "    # transforms.append(Resize(440)) # TBD: keep aspect ratio\n",
    "    transforms.append(ToTensor())\n",
    "    transforms.append(Normalize(mean=[.5, .5, .5],\n",
    "                                std=[.5, .5, .5]))\n",
    "\n",
    "    return Compose(transforms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "## 打印图片作为测试\n",
    "def cv2plt(img):\n",
    "    cv2.imshow(\"img\", cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    # print(new_image.astype(np.float32))\n",
    "    #  add below code\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "checkpoint = torch.load(f'./checkpoints/{model_select}', map_location=device)\n",
    "model = U2NET_full().to(device=device)\n",
    "\n",
    "if 'model' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "# 遍历每一张图片\n",
    "# for sample_select in samples:\n",
    "sample_select = samples[0]\n",
    "image = Image.open(sample_select).convert('RGB')\n",
    "\n",
    "#\n",
    "transforms = get_transform()\n",
    "alpha_image = None\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = transforms(image)\n",
    "    x = x.to(device=device).unsqueeze(dim=0)\n",
    "    y_hat, _ = model(x)\n",
    "\n",
    "    alpha_image = y_hat.mul(255)\n",
    "    alpha_image = Image.fromarray(alpha_image.squeeze().cpu().detach().numpy()).convert('L')\n",
    "    # st.image(alpha_image, width=800)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "image = np.asarray(image)\n",
    "# ##Option1: 绿背景\n",
    "# background = np.zeros(image.shape)\n",
    "# background[:, :] = [0, 177 / 255, 64 / 255]\n",
    "\n",
    "# ##Option2: 透明背景\n",
    "h, w, c = image.shape\n",
    "background = np.zeros((h, w, 3))\n",
    "\n",
    "alpha = y_hat.squeeze().cpu().detach()\n",
    "alpha = np.asarray(alpha)\n",
    "# alpha = (alpha * 255).astype(np.uint8)\n",
    "image = image.astype(np.float32) / 255\n",
    "\n",
    "foreground = estimate_foreground_ml(\n",
    "    image, alpha)  # , n_big_iterations=1, n_small_iterations=1, regularization=10e-10\n",
    "\n",
    "new_image = blend(foreground, background, alpha).astype(np.float32)\n",
    "cv2plt(new_image)\n",
    "## Combine the new_image (foreground + transparent background) with the alpha channel\n",
    "alpha = alpha[..., np.newaxis]\n",
    "rgba_image = np.concatenate((new_image, alpha), axis=2)\n",
    "rgba_image = (rgba_image * 255).astype(np.uint8)\n",
    "rgba_pil_image = Image.fromarray(rgba_image, mode=\"RGBA\")\n",
    "\n",
    "## Save the result as a PNG file\n",
    "rgba_pil_image.save(\"res.png\")\n",
    "\n",
    "del y_hat\n",
    "free_up_memory()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# image = np.asarray(image)\n",
    "# alpha = y_hat.squeeze().cpu().detach()\n",
    "# alpha = np.asarray(alpha)\n",
    "# image = image.astype(np.float32) / 255\n",
    "#\n",
    "# foreground = estimate_foreground_ml(image, alpha)\n",
    "#\n",
    "# h, w, c = image.shape\n",
    "# transparent_background = np.zeros((h, w, 3))\n",
    "#\n",
    "# new_image = blend(foreground, transparent_background, alpha)\n",
    "#\n",
    "# # Combine the new_image (foreground + transparent background) with the alpha channel\n",
    "# alpha = alpha[..., np.newaxis]\n",
    "# rgba_image = np.concatenate((new_image, alpha), axis=2)\n",
    "# rgba_image = (rgba_image * 255).astype(np.uint8)\n",
    "# rgba_pil_image = Image.fromarray(rgba_image, mode=\"RGBA\")\n",
    "#\n",
    "# # Save the result as a PNG file\n",
    "# rgba_pil_image.save(\"res.png\")\n",
    "#\n",
    "# del y_hat\n",
    "# free_up_memory()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_26288\\2450423326.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# alpha.show()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0malpha\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my_hat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0malpha\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0malpha\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;31m# alpha = (alpha * 255).astype(np.uint8)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "# 抠图（原图，mask图，输出前景图）\n",
    "image = np.asarray(image)\n",
    "\n",
    "# alpha = y_hat.squeeze().cpu().detach()\n",
    "# alpha = np.asarray(alpha)\n",
    "# alpha = Image.fromarray(((alpha * 255).astype('uint8')))\n",
    "# alpha.show()\n",
    "\n",
    "alpha = y_hat.squeeze().cpu().detach()\n",
    "alpha = np.asarray(alpha)\n",
    "# alpha = (alpha * 255).astype(np.uint8)\n",
    "image = image.astype(np.float32) / 255\n",
    "\n",
    "foreground = estimate_foreground_ml(\n",
    "    image, alpha)  # , n_big_iterations=1, n_small_iterations=1, regularization=10e-10\n",
    "\n",
    "# print(type(foreground))\n",
    "# cv2plt(foreground)\n",
    "\n",
    "# h, w, c = image.shape\n",
    "# img3 = np.zeros((h, w, 4))\n",
    "# img3[:, :, 0:3] = image\n",
    "# img3[:, :, 3] = alpha\n",
    "\n",
    "\n",
    "alpha = alpha[..., np.newaxis]\n",
    "rgba_image = np.concatenate((foreground, alpha), axis=2)\n",
    "rgba_image = (rgba_image * 255).astype(np.uint8)\n",
    "rgba_pil_image = Image.fromarray(rgba_image, mode=\"RGBA\")\n",
    "rgba_pil_image.save(\"res.png\")\n",
    "\n",
    "\n",
    "# img3 = Image.fromarray(img3, mode='RGBA')\n",
    "# cv2.imwrite(\"res.png\", img3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cv2plt(image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(alpha.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
